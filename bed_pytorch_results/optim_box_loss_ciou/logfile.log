OPTIM BED after reducing model and dropout, adding Loss Regularization and Weight Decay and BOX CIOU Loss
Starting script

Device: cuda
Learning Rate: 0.0005
Batch Size: 64
IMG DIMS: (224, 224)
W: 224
H: 224
SX: 7
SY: 7
B: 2
C: 2

Confidence Threshold: 0.2
IOU mAP Threshold: 0.5
IOU NMS Threshold: 0.3

Using OPTIM BED 224x224
Model shape is torch.Size([4, 7, 7, 12])
BED Model Arquitecture
OPTIM_BED(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (2): ReLU()
    (3): Dropout2d(p=0.3, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (7): ReLU()
    (8): Dropout2d(p=0.3, inplace=False)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (12): ReLU()
    (13): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (15): ReLU()
    (16): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (21): ReLU()
    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (23): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (24): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (25): ReLU()
    (26): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (28): ReLU()
    (29): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (30): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (31): ReLU()
    (32): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (34): ReLU()
    (35): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (36): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (37): ReLU()
    (38): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (40): ReLU()
    (41): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (42): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (44): ReLU()
    (45): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (47): ReLU()
    (48): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (50): ReLU()
    (51): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (52): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (53): ReLU()
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (56): ReLU()
    (57): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (58): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (59): ReLU()
    (60): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (61): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (62): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (63): ReLU()
    (64): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (66): ReLU()
    (67): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (68): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (69): ReLU()
    (70): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (71): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (72): ReLU()
    (73): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (74): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (75): ReLU()
    (76): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
)

Trainable parameters = 463104
Total parameters = 463104

Using YoloLossCIOU_2BBox

TRAIN DFIRE dataset
Removed wrong images: 0
Removed due to overlapping: 546
Removed due to more than 3: 1764
TRAIN DFS dataset
Removed wrong images: 0
Removed due to overlapping: 274
Removed due to more than 3: 1199
Concatenate Train DFire and DFS datasets
Train dataset len: 21146

TEST DFire dataset
Removed wrong images: 0
Removed due to overlapping: 118
Removed due to more than 3: 445
TEST DFS dataset
Removed wrong images: 0
Removed due to overlapping: 72
Removed due to more than 3: 309
Concatenate Test DFire and DFS datasets
Test dataset len: 5296

***Start Training: 16:58:50


=== EPOCH 0/119 ===
Learning Rate = 0.0005
Starting script

Device: cuda
Learning Rate: 0.0005
Batch Size: 64
IMG DIMS: (224, 224)
W: 224
H: 224
SX: 7
SY: 7
B: 2
C: 2

Confidence Threshold: 0.2
IOU mAP Threshold: 0.5
IOU NMS Threshold: 0.3

Using OPTIM BED 224x224
Model shape is torch.Size([4, 7, 7, 12])
BED Model Arquitecture
OPTIM_BED(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (2): ReLU()
    (3): Dropout2d(p=0.3, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (7): ReLU()
    (8): Dropout2d(p=0.3, inplace=False)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (12): ReLU()
    (13): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (15): ReLU()
    (16): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (21): ReLU()
    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (23): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (24): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (25): ReLU()
    (26): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (28): ReLU()
    (29): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (30): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (31): ReLU()
    (32): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (34): ReLU()
    (35): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (36): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (37): ReLU()
    (38): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (40): ReLU()
    (41): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (42): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (44): ReLU()
    (45): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (47): ReLU()
    (48): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (50): ReLU()
    (51): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (52): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (53): ReLU()
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (56): ReLU()
    (57): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (58): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (59): ReLU()
    (60): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (61): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (62): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (63): ReLU()
    (64): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (66): ReLU()
    (67): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (68): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (69): ReLU()
    (70): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (71): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (72): ReLU()
    (73): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (74): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (75): ReLU()
    (76): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
)

Trainable parameters = 463104
Total parameters = 463104

Using YoloLossCIOU_2BBox

TRAIN DFIRE dataset
Removed wrong images: 0
Removed due to overlapping: 546
Removed due to more than 3: 1764
TRAIN DFS dataset
Removed wrong images: 0
Removed due to overlapping: 274
Removed due to more than 3: 1199
Concatenate Train DFire and DFS datasets
Train dataset len: 21146

TEST DFire dataset
OPTIM BED after reducing model and dropout, adding Loss Regularization and Weight Decay and BOX CIOU Loss
Starting script

Device: cuda
Learning Rate: 0.0005
Batch Size: 64
IMG DIMS: (224, 224)
W: 224
H: 224
SX: 7
SY: 7
B: 2
C: 2

Confidence Threshold: 0.2
IOU mAP Threshold: 0.5
IOU NMS Threshold: 0.3

Using OPTIM BED 224x224
Model shape is torch.Size([4, 7, 7, 12])
BED Model Arquitecture
OPTIM_BED(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (2): ReLU()
    (3): Dropout2d(p=0.3, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (7): ReLU()
    (8): Dropout2d(p=0.3, inplace=False)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (12): ReLU()
    (13): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (15): ReLU()
    (16): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (21): ReLU()
    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (23): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (24): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (25): ReLU()
    (26): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (28): ReLU()
    (29): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (30): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (31): ReLU()
    (32): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (34): ReLU()
    (35): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (36): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (37): ReLU()
    (38): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (40): ReLU()
    (41): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (42): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (44): ReLU()
    (45): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (47): ReLU()
    (48): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (50): ReLU()
    (51): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (52): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (53): ReLU()
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (56): ReLU()
    (57): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (58): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (59): ReLU()
    (60): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (61): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (62): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (63): ReLU()
    (64): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (66): ReLU()
    (67): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (68): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (69): ReLU()
    (70): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (71): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (72): ReLU()
    (73): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (74): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (75): ReLU()
    (76): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
)

Trainable parameters = 463104
Total parameters = 463104

Using YoloLossCIOU_2BBox

TRAIN DFIRE dataset
OPTIM BED after reducing model and dropout, adding Loss Regularization and Weight Decay and BOX CIOU Loss
Starting script

Device: cuda
Learning Rate: 0.0005
Batch Size: 64
IMG DIMS: (224, 224)
W: 224
H: 224
SX: 7
SY: 7
B: 2
C: 2

Confidence Threshold: 0.2
IOU mAP Threshold: 0.5
IOU NMS Threshold: 0.3

Using OPTIM BED 224x224
Model shape is torch.Size([4, 7, 7, 12])
BED Model Arquitecture
OPTIM_BED(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (2): ReLU()
    (3): Dropout2d(p=0.3, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (7): ReLU()
    (8): Dropout2d(p=0.3, inplace=False)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (12): ReLU()
    (13): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (15): ReLU()
    (16): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (21): ReLU()
    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (23): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (24): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (25): ReLU()
    (26): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (28): ReLU()
    (29): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (30): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (31): ReLU()
    (32): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (34): ReLU()
    (35): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (36): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (37): ReLU()
    (38): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (40): ReLU()
    (41): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (42): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (44): ReLU()
    (45): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (47): ReLU()
    (48): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (50): ReLU()
    (51): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (52): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (53): ReLU()
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (56): ReLU()
    (57): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (58): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (59): ReLU()
    (60): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (61): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (62): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (63): ReLU()
    (64): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (66): ReLU()
    (67): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (68): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (69): ReLU()
    (70): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (71): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (72): ReLU()
    (73): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (74): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (75): ReLU()
    (76): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
)

Trainable parameters = 463104
Total parameters = 463104

Using YoloLossCIOU_2BBox

TRAIN DFIRE dataset
Removed wrong images: 0
Removed due to overlapping: 546
Removed due to more than 3: 1764
TRAIN DFS dataset
Removed wrong images: 0
Removed due to overlapping: 279
Removed due to more than 3: 1199
Concatenate Train DFire and DFS datasets
Train dataset len: 21150

TEST DFire dataset
Removed wrong images: 0
Removed due to overlapping: 118
Removed due to more than 3: 445
TEST DFS dataset
Removed wrong images: 0
Removed due to overlapping: 67
Removed due to more than 3: 309
Concatenate Test DFire and DFS datasets
Test dataset len: 5292

***Start Training: 18:09:41


=== EPOCH 0/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
461.041     |178.958     |49.206      |188.896     |19.059      

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
323.313     |178.588     |57.127      |75.086      |12.511      

Saving model with new best validation loss: 323.313

=== EPOCH 1/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
305.800     |162.145     |59.761      |48.180      |11.230      

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
261.712     |166.347     |62.992      |24.127      |8.245       

Saving model with new best validation loss: 261.712

=== EPOCH 2/119 ===
Learning Rate = 0.0005
OPTIM BED after reducing model and dropout, adding Loss Regularization and Weight Decay and BOX CIOU Loss
Starting script

Device: cuda
Learning Rate: 0.0005
Batch Size: 64
IMG DIMS: (224, 224)
W: 224
H: 224
SX: 7
SY: 7
B: 2
C: 2

Confidence Threshold: 0.2
IOU mAP Threshold: 0.5
IOU NMS Threshold: 0.3

Using OPTIM BED 224x224
Model shape is torch.Size([4, 7, 7, 12])
BED Model Arquitecture
OPTIM_BED(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (2): ReLU()
    (3): Dropout2d(p=0.3, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (7): ReLU()
    (8): Dropout2d(p=0.3, inplace=False)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (12): ReLU()
    (13): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (15): ReLU()
    (16): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (21): ReLU()
    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (23): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (24): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (25): ReLU()
    (26): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (28): ReLU()
    (29): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (30): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (31): ReLU()
    (32): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (34): ReLU()
    (35): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (36): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (37): ReLU()
    (38): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (40): ReLU()
    (41): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (42): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (44): ReLU()
    (45): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (47): ReLU()
    (48): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (50): ReLU()
    (51): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (52): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (53): ReLU()
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (56): ReLU()
    (57): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (58): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (59): ReLU()
    (60): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (61): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (62): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (63): ReLU()
    (64): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (66): ReLU()
    (67): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (68): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (69): ReLU()
    (70): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (71): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (72): ReLU()
    (73): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (74): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (75): ReLU()
    (76): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
)

Trainable parameters = 463104
Total parameters = 463104

Using YoloLossCIOU_2BBox

TRAIN DFIRE dataset
Removed wrong images: 0
Removed due to overlapping: 546
Removed due to more than 3: 1764
TRAIN DFS dataset
Removed wrong images: 0
Removed due to overlapping: 269
Removed due to more than 3: 1206
Concatenate Train DFire and DFS datasets
Train dataset len: 21143

TEST DFire dataset
Removed wrong images: 0
Removed due to overlapping: 118
Removed due to more than 3: 445
TEST DFS dataset
Removed wrong images: 0
Removed due to overlapping: 77
Removed due to more than 3: 302
Concatenate Test DFire and DFS datasets
Test dataset len: 5299

***Start Training: 18:31:03


=== EPOCH 0/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
479.134     |184.593     |46.693      |202.237     |20.671      

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
322.440     |184.986     |55.891      |67.284      |14.279      

Saving model with new best validation loss: 322.440

=== EPOCH 1/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
314.270     |170.694     |59.261      |47.320      |12.593      

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
267.777     |171.639     |62.501      |24.423      |9.214       

Saving model with new best validation loss: 267.777

=== EPOCH 2/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
277.189     |158.463     |62.285      |22.695      |9.766       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
249.676     |164.854     |61.336      |15.658      |7.828       

Saving model with new best validation loss: 249.676

=== EPOCH 3/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
263.377     |151.883     |63.216      |15.607      |9.017       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
241.158     |158.865     |63.176      |11.218      |7.898       

Saving model with new best validation loss: 241.158

=== EPOCH 4/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
253.280     |146.556     |63.781      |11.541      |8.042       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
232.467     |154.564     |61.394      |10.159      |6.350       

Validation mAP: 0.063

Saving model with new best val mAP: 0.063

Saving model with new best validation loss: 232.467

=== EPOCH 5/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
244.888     |140.886     |62.756      |10.498      |7.643       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
225.818     |149.818     |61.394      |8.600       |6.006       

Saving model with new best validation loss: 225.818

=== EPOCH 6/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
239.031     |137.600     |61.175      |10.318      |7.059       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
219.061     |146.085     |56.364      |10.865      |5.747       

Saving model with new best validation loss: 219.061

=== EPOCH 7/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
234.078     |135.276     |58.822      |10.764      |6.559       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
215.052     |144.179     |54.880      |10.543      |5.450       

Saving model with new best validation loss: 215.052

=== EPOCH 8/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
229.600     |133.178     |56.541      |11.074      |6.357       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
211.739     |142.447     |53.964      |10.009      |5.320       

Saving model with new best validation loss: 211.739

=== EPOCH 9/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
224.763     |129.756     |55.786      |10.782      |6.183       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
208.402     |140.052     |52.940      |10.135      |5.275       

Validation mAP: 0.151

Saving model with new best val mAP: 0.151

Saving model with new best validation loss: 208.402

=== EPOCH 10/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
221.815     |128.479     |54.613      |10.682      |5.957       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
206.198     |138.908     |51.300      |10.773      |5.216       

Saving model with new best validation loss: 206.198

=== EPOCH 11/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
220.687     |127.941     |54.379      |10.501      |5.943       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
204.682     |138.277     |52.587      |8.803       |5.015       

Saving model with new best validation loss: 204.682

=== EPOCH 12/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
217.738     |126.199     |53.646      |10.439      |5.673       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
203.164     |136.800     |48.469      |13.092      |4.802       

Saving model with new best validation loss: 203.164

=== EPOCH 13/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
216.264     |125.435     |53.169      |10.435      |5.578       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
199.675     |134.774     |51.045      |8.951       |4.904       

Saving model with new best validation loss: 199.675

=== EPOCH 14/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
213.974     |123.825     |52.632      |10.459      |5.520       

Train mAP: 0.225

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
199.312     |135.511     |49.415      |9.841       |4.545       

Validation mAP: 0.220

Saving model with new best val mAP: 0.220

Saving model with new best validation loss: 199.312

=== EPOCH 15/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
213.007     |123.316     |52.256      |10.435      |5.557       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
197.732     |133.668     |48.412      |11.094      |4.558       

Saving model with new best validation loss: 197.732

=== EPOCH 16/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
210.225     |121.364     |51.713      |10.428      |5.367       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
195.489     |132.852     |48.188      |10.134      |4.315       

Saving model with new best validation loss: 195.489

=== EPOCH 17/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
208.737     |120.732     |50.858      |10.688      |5.188       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
194.400     |131.888     |48.965      |9.054       |4.493       

Saving model with new best validation loss: 194.400

=== EPOCH 18/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
207.409     |120.038     |50.448      |10.605      |5.108       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
192.561     |130.996     |47.947      |9.278       |4.340       

Saving model with new best validation loss: 192.561

=== EPOCH 19/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
205.331     |118.741     |49.750      |10.646      |5.050       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
193.411     |131.895     |46.855      |10.277      |4.383       

Validation mAP: 0.232

Saving model with new best val mAP: 0.232

=== EPOCH 20/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
204.654     |118.358     |49.504      |10.867      |4.839       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
191.880     |129.809     |48.797      |8.813       |4.461       

Saving model with new best validation loss: 191.880

=== EPOCH 21/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
203.270     |117.356     |49.105      |10.760      |5.016       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
188.565     |128.249     |46.146      |9.840       |4.330       

Saving model with new best validation loss: 188.565

=== EPOCH 22/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
201.710     |116.711     |48.545      |10.797      |4.661       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
188.014     |127.733     |44.484      |11.484      |4.313       

Saving model with new best validation loss: 188.014

=== EPOCH 23/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
200.906     |116.444     |47.901      |10.952      |4.644       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
186.484     |127.543     |44.073      |10.753      |4.114       

Saving model with new best validation loss: 186.484

=== EPOCH 24/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
199.756     |115.685     |47.432      |11.028      |4.677       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
185.768     |126.426     |43.384      |11.408      |4.550       

Validation mAP: 0.230

Saving model with new best validation loss: 185.768

=== EPOCH 25/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
199.175     |115.311     |47.353      |11.077      |4.522       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
187.433     |128.365     |45.298      |9.432       |4.338       

=== EPOCH 26/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
197.588     |114.046     |46.916      |11.036      |4.693       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
183.747     |125.422     |41.044      |13.002      |4.279       

Saving model with new best validation loss: 183.747

=== EPOCH 27/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
196.245     |113.473     |46.112      |11.210      |4.570       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
181.824     |124.046     |40.305      |13.552      |3.921       

Saving model with new best validation loss: 181.824

=== EPOCH 28/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
195.911     |113.039     |46.183      |11.198      |4.618       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
183.255     |125.941     |42.369      |10.864      |4.081       

=== EPOCH 29/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
194.214     |111.874     |45.703      |11.261      |4.508       

Train mAP: 0.271

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
180.518     |124.676     |39.374      |12.696      |3.772       

Validation mAP: 0.249

Saving model with new best val mAP: 0.249

Saving model with new best validation loss: 180.518

=== EPOCH 30/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
193.261     |111.670     |45.322      |11.092      |4.322       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
178.977     |123.114     |41.727      |10.346      |3.790       

Saving model with new best validation loss: 178.977

=== EPOCH 31/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
192.535     |111.405     |44.765      |11.262      |4.243       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
179.674     |122.866     |41.851      |10.999      |3.957       

=== EPOCH 32/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
192.221     |110.964     |44.938      |11.318      |4.128       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
178.456     |121.946     |39.412      |13.180      |3.918       

Saving model with new best validation loss: 178.456

=== EPOCH 33/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
190.588     |109.575     |44.704      |11.231      |4.191       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
177.913     |122.329     |41.000      |10.671      |3.912       

Saving model with new best validation loss: 177.913

=== EPOCH 34/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
189.972     |109.656     |43.879      |11.303      |4.242       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
178.410     |122.157     |41.484      |10.827      |3.943       

Validation mAP: 0.287

Saving model with new best val mAP: 0.287

=== EPOCH 35/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
189.394     |109.151     |44.189      |11.127      |4.028       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
177.890     |122.140     |38.704      |13.348      |3.698       

Saving model with new best validation loss: 177.890

=== EPOCH 36/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
188.784     |108.736     |43.656      |11.275      |4.209       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
176.612     |121.597     |40.824      |10.560      |3.630       

Saving model with new best validation loss: 176.612

=== EPOCH 37/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
188.839     |109.064     |43.653      |11.242      |3.960       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
177.300     |121.116     |38.962      |13.657      |3.565       

=== EPOCH 38/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
187.543     |107.793     |43.402      |11.226      |4.191       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
173.977     |119.730     |39.227      |11.249      |3.770       

Saving model with new best validation loss: 173.977

=== EPOCH 39/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
186.796     |107.387     |43.299      |11.290      |3.879       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
173.306     |118.990     |36.210      |14.537      |3.569       

Validation mAP: 0.320

Saving model with new best val mAP: 0.320

Saving model with new best validation loss: 173.306

=== EPOCH 40/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
186.118     |106.760     |42.991      |11.388      |4.017       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
174.522     |120.164     |40.187      |10.524      |3.647       

=== EPOCH 41/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
185.985     |106.932     |42.848      |11.363      |3.864       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
172.964     |118.956     |38.407      |11.943      |3.658       

Saving model with new best validation loss: 172.964

=== EPOCH 42/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
184.590     |105.950     |42.614      |11.208      |3.829       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
172.225     |118.579     |39.082      |11.003      |3.562       

Saving model with new best validation loss: 172.225

=== EPOCH 43/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
184.379     |106.053     |42.303      |11.242      |3.769       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
171.421     |117.664     |38.586      |11.362      |3.808       

Saving model with new best validation loss: 171.421

=== EPOCH 44/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
184.421     |105.362     |42.582      |11.378      |4.073       

Train mAP: 0.338

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
171.254     |117.220     |40.075      |10.543      |3.417       

Validation mAP: 0.331

Saving model with new best val mAP: 0.331

Saving model with new best validation loss: 171.254

=== EPOCH 45/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
183.478     |105.627     |41.812      |11.248      |3.754       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
170.365     |116.736     |36.495      |13.409      |3.724       

Saving model with new best validation loss: 170.365

=== EPOCH 46/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
183.526     |105.129     |42.101      |11.373      |3.870       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
169.687     |116.535     |38.034      |11.722      |3.397       

Saving model with new best validation loss: 169.687

=== EPOCH 47/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
182.602     |104.805     |41.675      |11.235      |3.812       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
173.193     |118.187     |36.047      |15.272      |3.687       

=== EPOCH 48/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
182.177     |104.472     |41.551      |11.312      |3.745       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
171.791     |118.058     |38.180      |11.814      |3.739       

=== EPOCH 49/119 ===
Learning Rate = 0.0005

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
181.245     |103.794     |41.368      |11.303      |3.666       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
169.770     |116.978     |37.484      |11.713      |3.595       

Validation mAP: 0.303

=== EPOCH 50/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
179.211     |102.458     |40.635      |11.313      |3.705       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
168.733     |116.275     |36.372      |12.605      |3.481       

Saving model with new best validation loss: 168.733

=== EPOCH 51/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
178.820     |102.377     |40.482      |11.319      |3.577       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
167.217     |115.037     |37.190      |11.421      |3.568       

Saving model with new best validation loss: 167.217

=== EPOCH 52/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
178.433     |101.968     |40.655      |11.231      |3.538       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
168.404     |115.405     |37.533      |12.159      |3.308       

=== EPOCH 53/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
177.087     |101.321     |40.074      |11.165      |3.508       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
167.049     |114.909     |37.421      |11.227      |3.492       

Saving model with new best validation loss: 167.049

=== EPOCH 54/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
176.661     |101.082     |39.659      |11.397      |3.517       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
167.108     |114.868     |38.684      |9.944       |3.612       

Validation mAP: 0.344

Saving model with new best val mAP: 0.344

=== EPOCH 55/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
176.540     |100.754     |40.111      |11.240      |3.435       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
166.355     |114.307     |36.994      |11.485      |3.568       

Saving model with new best validation loss: 166.355

=== EPOCH 56/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
175.415     |100.119     |39.517      |11.379      |3.410       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
167.766     |115.475     |37.456      |11.237      |3.597       

=== EPOCH 57/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
175.747     |100.324     |39.499      |11.334      |3.610       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
165.386     |113.946     |37.823      |9.945       |3.672       

Saving model with new best validation loss: 165.386

=== EPOCH 58/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
175.372     |100.489     |39.375      |11.189      |3.344       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
166.310     |114.458     |37.996      |10.277      |3.579       

=== EPOCH 59/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
174.617     |99.551      |39.412      |11.173      |3.510       

Train mAP: 0.381

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
164.805     |113.415     |36.624      |11.348      |3.418       

Validation mAP: 0.349

Saving model with new best val mAP: 0.349

Saving model with new best validation loss: 164.805

=== EPOCH 60/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
174.089     |99.403      |39.128      |11.231      |3.362       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
163.034     |112.078     |35.377      |12.259      |3.320       

Saving model with new best validation loss: 163.034

=== EPOCH 61/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
173.759     |99.068      |39.196      |11.213      |3.323       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
165.208     |113.677     |36.886      |11.299      |3.345       

=== EPOCH 62/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
173.687     |99.017      |39.149      |11.206      |3.353       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
165.272     |113.760     |36.839      |11.087      |3.586       

=== EPOCH 63/119 ===
Learning Rate = 0.0004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
173.174     |99.011      |38.733      |11.116      |3.352       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
163.380     |112.409     |35.093      |12.343      |3.535       

=== EPOCH 64/119 ===
Learning Rate = 0.00032

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
171.267     |97.653      |38.202      |11.217      |3.254       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
162.059     |111.481     |35.827      |11.135      |3.616       

Validation mAP: 0.377

Saving model with new best val mAP: 0.377

Saving model with new best validation loss: 162.059

=== EPOCH 65/119 ===
Learning Rate = 0.00032

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
170.387     |97.200      |37.896      |11.133      |3.249       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
163.445     |111.458     |37.913      |10.414      |3.661       

=== EPOCH 66/119 ===
Learning Rate = 0.00032

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
170.453     |97.329      |38.057      |11.052      |3.134       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
163.150     |112.392     |36.349      |11.007      |3.401       

=== EPOCH 67/119 ===
Learning Rate = 0.00032

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
168.914     |96.172      |37.627      |11.118      |3.133       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
162.744     |111.754     |38.638      |8.949       |3.404       

=== EPOCH 68/119 ===
Learning Rate = 0.00025600000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
167.825     |95.607      |37.359      |10.893      |3.132       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
161.449     |111.033     |33.155      |13.876      |3.384       

Saving model with new best validation loss: 161.449

=== EPOCH 69/119 ===
Learning Rate = 0.00025600000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
167.542     |95.779      |36.836      |10.978      |3.157       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
160.387     |110.723     |35.239      |11.160      |3.264       

Validation mAP: 0.379

Saving model with new best val mAP: 0.379

Saving model with new best validation loss: 160.387

=== EPOCH 70/119 ===
Learning Rate = 0.00025600000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
165.694     |94.294      |36.734      |10.908      |3.005       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
160.357     |110.665     |34.532      |11.692      |3.468       

Saving model with new best validation loss: 160.357

=== EPOCH 71/119 ===
Learning Rate = 0.00025600000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
166.032     |94.433      |36.875      |10.900      |3.102       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
160.329     |110.347     |35.924      |10.733      |3.325       

Saving model with new best validation loss: 160.329

=== EPOCH 72/119 ===
Learning Rate = 0.00025600000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
165.582     |94.571      |36.501      |10.823      |2.994       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
160.676     |110.695     |34.148      |12.396      |3.436       

=== EPOCH 73/119 ===
Learning Rate = 0.00020480000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
164.392     |94.002      |35.963      |10.840      |2.924       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
160.203     |110.141     |35.951      |10.691      |3.420       

Saving model with new best validation loss: 160.203

=== EPOCH 74/119 ===
Learning Rate = 0.00020480000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
163.887     |93.093      |36.345      |10.857      |2.965       

Train mAP: 0.429

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
160.719     |110.793     |34.689      |11.914      |3.323       

Validation mAP: 0.357

=== EPOCH 75/119 ===
Learning Rate = 0.00020480000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
162.977     |92.819      |35.933      |10.649      |2.980       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
158.301     |109.580     |34.131      |11.452      |3.138       

Saving model with new best validation loss: 158.301

=== EPOCH 76/119 ===
Learning Rate = 0.00020480000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
162.434     |92.363      |35.879      |10.716      |2.909       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
158.866     |109.286     |34.677      |11.677      |3.225       

=== EPOCH 77/119 ===
Learning Rate = 0.00020480000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
162.934     |92.809      |35.749      |10.957      |2.880       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
157.819     |108.825     |31.892      |13.825      |3.277       

Saving model with new best validation loss: 157.819

=== EPOCH 78/119 ===
Learning Rate = 0.00020480000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
162.366     |92.750      |35.392      |10.832      |2.878       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
159.712     |110.194     |33.732      |12.428      |3.358       

=== EPOCH 79/119 ===
Learning Rate = 0.00020480000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
161.528     |91.978      |35.501      |10.694      |2.865       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
159.648     |109.557     |36.035      |10.483      |3.574       

Validation mAP: 0.378

=== EPOCH 80/119 ===
Learning Rate = 0.00020480000000000004

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
161.177     |91.969      |35.221      |10.664      |2.860       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
157.890     |108.666     |33.741      |12.227      |3.256       

=== EPOCH 81/119 ===
Learning Rate = 0.00016384000000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
160.594     |91.621      |35.054      |10.740      |2.745       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
158.089     |108.899     |34.128      |11.765      |3.297       

=== EPOCH 82/119 ===
Learning Rate = 0.00016384000000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
159.151     |90.604      |34.715      |10.654      |2.773       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
157.289     |108.126     |33.776      |12.024      |3.362       

Saving model with new best validation loss: 157.289

=== EPOCH 83/119 ===
Learning Rate = 0.00016384000000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
159.434     |90.930      |34.747      |10.545      |2.832       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
157.450     |108.514     |35.144      |10.521      |3.271       

=== EPOCH 84/119 ===
Learning Rate = 0.00016384000000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
158.339     |90.531      |34.398      |10.359      |2.696       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
157.989     |108.609     |35.514      |10.568      |3.298       

Validation mAP: 0.402

Saving model with new best val mAP: 0.402

=== EPOCH 85/119 ===
Learning Rate = 0.00016384000000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
158.493     |90.336      |34.435      |10.529      |2.860       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
157.661     |108.581     |34.436      |11.489      |3.154       

=== EPOCH 86/119 ===
Learning Rate = 0.00013107200000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
157.220     |89.757      |33.922      |10.496      |2.739       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.634     |107.758     |35.211      |10.493      |3.171       

Saving model with new best validation loss: 156.634

=== EPOCH 87/119 ===
Learning Rate = 0.00013107200000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
157.131     |89.560      |34.076      |10.328      |2.885       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.556     |107.760     |33.641      |11.949      |3.206       

Saving model with new best validation loss: 156.556

=== EPOCH 88/119 ===
Learning Rate = 0.00013107200000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.905     |89.292      |34.186      |10.511      |2.660       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.801     |107.815     |35.542      |10.196      |3.248       

=== EPOCH 89/119 ===
Learning Rate = 0.00013107200000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.610     |89.220      |34.167      |10.251      |2.738       

Train mAP: 0.479

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
157.139     |108.145     |35.668      |10.120      |3.206       

Validation mAP: 0.399

=== EPOCH 90/119 ===
Learning Rate = 0.00010485760000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.300     |88.501      |33.668      |10.295      |2.627       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.569     |107.788     |33.957      |11.644      |3.180       

=== EPOCH 91/119 ===
Learning Rate = 0.00010485760000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.800     |89.004      |33.633      |10.368      |2.608       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.011     |107.454     |33.272      |12.120      |3.165       

Saving model with new best validation loss: 156.011

=== EPOCH 92/119 ===
Learning Rate = 0.00010485760000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.162     |88.689      |33.321      |10.336      |2.649       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.357     |107.689     |34.115      |11.280      |3.272       

=== EPOCH 93/119 ===
Learning Rate = 0.00010485760000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.055     |88.522      |33.533      |10.242      |2.610       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.506     |107.780     |33.392      |12.123      |3.211       

=== EPOCH 94/119 ===
Learning Rate = 0.00010485760000000006

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.663     |88.250      |33.259      |10.351      |2.674       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.503     |107.554     |33.656      |12.013      |3.280       

Validation mAP: 0.412

Saving model with new best val mAP: 0.412

=== EPOCH 95/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.138     |87.928      |33.214      |10.347      |2.539       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.227     |107.442     |34.594      |10.950      |3.241       

=== EPOCH 96/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.125     |88.023      |33.119      |10.239      |2.652       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
156.136     |107.499     |34.221      |11.194      |3.222       

=== EPOCH 97/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
153.372     |87.463      |32.997      |10.202      |2.634       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.532     |106.821     |34.110      |11.383      |3.218       

Saving model with new best validation loss: 155.532

=== EPOCH 98/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
152.738     |87.097      |32.942      |10.090      |2.552       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.993     |107.228     |33.537      |11.945      |3.283       

=== EPOCH 99/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
152.605     |86.745      |32.973      |10.251      |2.596       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.411     |106.761     |33.327      |12.094      |3.229       

Validation mAP: 0.414

Saving model with new best val mAP: 0.414

Saving model with new best validation loss: 155.411

=== EPOCH 100/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
153.100     |87.334      |32.975      |10.250      |2.519       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.920     |106.994     |35.299      |10.355      |3.273       

=== EPOCH 101/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
152.672     |87.065      |32.601      |10.316      |2.683       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.255     |106.439     |33.242      |12.343      |3.231       

Saving model with new best validation loss: 155.255

=== EPOCH 102/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
152.205     |86.818      |32.599      |10.161      |2.636       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.467     |106.738     |33.663      |11.942      |3.123       

=== EPOCH 103/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
151.839     |86.710      |32.556      |10.091      |2.507       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.367     |106.659     |34.313      |11.183      |3.212       

=== EPOCH 104/119 ===
Learning Rate = 8.388608000000005e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
152.271     |86.952      |32.737      |10.182      |2.440       

Train mAP: 0.503

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.846     |107.329     |33.731      |11.648      |3.138       

Validation mAP: 0.404

=== EPOCH 105/119 ===
Learning Rate = 6.710886400000004e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
151.655     |86.336      |32.590      |10.086      |2.696       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.469     |106.771     |33.607      |11.929      |3.162       

=== EPOCH 106/119 ===
Learning Rate = 6.710886400000004e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
151.291     |86.394      |32.347      |10.108      |2.511       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.548     |106.795     |34.013      |11.603      |3.137       

=== EPOCH 107/119 ===
Learning Rate = 6.710886400000004e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
151.006     |86.056      |32.468      |10.005      |2.558       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.179     |106.710     |33.089      |12.244      |3.136       

Saving model with new best validation loss: 155.179

=== EPOCH 108/119 ===
Learning Rate = 5.3687091200000036e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
151.042     |86.127      |32.408      |10.076      |2.527       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.535     |106.115     |34.322      |10.993      |3.105       

Saving model with new best validation loss: 154.535

=== EPOCH 109/119 ===
Learning Rate = 5.3687091200000036e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
149.961     |85.634      |31.969      |9.950       |2.516       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.006     |106.454     |33.498      |11.918      |3.135       

Validation mAP: 0.430

Saving model with new best val mAP: 0.430

=== EPOCH 110/119 ===
Learning Rate = 5.3687091200000036e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
150.055     |85.759      |31.825      |10.071      |2.521       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.476     |106.121     |33.679      |11.568      |3.108       

Saving model with new best validation loss: 154.476

=== EPOCH 111/119 ===
Learning Rate = 5.3687091200000036e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
149.468     |85.356      |31.970      |9.854       |2.420       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.907     |106.162     |33.809      |11.764      |3.172       

=== EPOCH 112/119 ===
Learning Rate = 4.2949672960000034e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
149.364     |85.233      |31.818      |9.960       |2.496       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.062     |106.470     |33.696      |11.765      |3.131       

=== EPOCH 113/119 ===
Learning Rate = 4.2949672960000034e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
149.568     |85.307      |32.042      |9.887       |2.485       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.716     |106.225     |33.738      |11.578      |3.175       

=== EPOCH 114/119 ===
Learning Rate = 4.2949672960000034e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
149.330     |85.255      |31.665      |10.014      |2.559       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
155.033     |106.499     |32.711      |12.700      |3.123       

Validation mAP: 0.423

=== EPOCH 115/119 ===
Learning Rate = 3.435973836800003e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
148.398     |84.753      |31.469      |9.949       |2.398       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.874     |106.355     |34.102      |11.199      |3.218       

=== EPOCH 116/119 ===
Learning Rate = 3.435973836800003e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
148.581     |84.840      |31.728      |9.783       |2.409       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.408     |105.952     |33.602      |11.663      |3.191       

Saving model with new best validation loss: 154.408

=== EPOCH 117/119 ===
Learning Rate = 3.435973836800003e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
148.399     |84.458      |31.974      |9.724       |2.432       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.462     |106.071     |33.383      |11.886      |3.122       

=== EPOCH 118/119 ===
Learning Rate = 3.435973836800003e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
148.298     |84.846      |31.340      |9.800       |2.509       

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.471     |105.974     |33.449      |11.918      |3.130       

=== EPOCH 119/119 ===
Learning Rate = 3.435973836800003e-05

TRAIN losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
148.819     |85.115      |31.749      |9.850       |2.311       

Train mAP: 0.529

VAL losses
Total Loss  |Box Loss    |Conf Loss   |No Obj Loss |Class Loss  
------------ ------------ ------------ ------------ ------------
154.707     |105.985     |33.690      |11.802      |3.229       

Validation mAP: 0.427
Saving last model

***Script finished: 01:27:24

Time elapsed: 6:56:20.959674
OPTIM BED after reducing model and dropout, adding Loss Regularization and Weight Decay and BOX CIOU Loss
Starting script

Device: cuda
Learning Rate: 0.0005
Batch Size: 64
IMG DIMS: (224, 224)
W: 224
H: 224
SX: 7
SY: 7
B: 2
C: 2

Confidence Threshold: 0.2
IOU mAP Threshold: 0.5
IOU NMS Threshold: 0.3

Using OPTIM BED 224x224
Model shape is torch.Size([4, 7, 7, 12])
BED Model Arquitecture
OPTIM_BED(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (2): ReLU()
    (3): Dropout2d(p=0.3, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (7): ReLU()
    (8): Dropout2d(p=0.3, inplace=False)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (12): ReLU()
    (13): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (15): ReLU()
    (16): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (18): ReLU()
    (19): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (21): ReLU()
    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (23): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (24): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (25): ReLU()
    (26): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (28): ReLU()
    (29): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (30): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (31): ReLU()
    (32): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (34): ReLU()
    (35): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (36): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (37): ReLU()
    (38): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (40): ReLU()
    (41): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (42): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (44): ReLU()
    (45): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (46): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (47): ReLU()
    (48): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (50): ReLU()
    (51): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (52): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (53): ReLU()
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (56): ReLU()
    (57): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (58): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (59): ReLU()
    (60): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (61): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (62): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (63): ReLU()
    (64): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (66): ReLU()
    (67): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (68): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (69): ReLU()
    (70): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (71): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (72): ReLU()
    (73): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (74): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    (75): ReLU()
    (76): Conv2d(16, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
)

Trainable parameters = 463104
Total parameters = 463104

Using YoloLossCIOU_2BBox

TRAIN DFIRE dataset
